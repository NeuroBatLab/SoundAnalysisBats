{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioSound Tutorial 5.  Using the Spectrogram as features for classifiers.\n",
    "### In tutorial 4, you learned how to use predefined acoustical features such as pitch saliency to classify sounds.  Here you will use a spectrogram.  The plotDiscriminate routine performs a PCA on these large feature spaces to prevent over-fitting \n",
    "\n",
    "Some things to note:  The spectrogram approach will only work if all BioSound files have the same size spectrogam.  This usually means the same sound length and the same time-frequency scale. Here spectrograms are cut to the smallest soud. It also makes sense to have a logical alignment since the approach will be sensitive to shifts. This code can easily be modified to also use the modulation power spectrum. \n",
    "The modulation spectrum allows for variable size sounds and is insensitive to shifts but the analysis window for the MPS must be identical and it must be based on spectrograms that were obtained with the same time-frequency scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Loading all the dependencies.  \n",
    "### numpy, matplotlib and soundsig should have been installed when you installed soundsig.  You might have to also install pandas, pickle and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import math, pandas and soundsig libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from soundsig.sound import BioSound \n",
    "#from soundsig.discriminate import discriminatePlot\n",
    "import sys\n",
    "sys.path.append('./soundsig/soundsig')\n",
    "from discriminate import discriminatePlot\n",
    "\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats.mstats import zscore\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Specifying the location of the sound files in BioSound format (h5 files).\n",
    "\n",
    "YOU WILL WANT TO CHANGE TO FOLLOWING CODE TO POINT TO THE RIGHT PLACE  \n",
    "You will also want to change the location for storing the pandas table.  \n",
    "Note that you might want to also change the name of the h5 file that stores all of the spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Go to the folder that has the h5 files corresponding to the BioSound objects.\n",
    "os.chdir('/Users/tobias/Documents/BioSoundTutorial-master/BatCalls/h5files')\n",
    "\n",
    "# Some output files\n",
    "tableStore = '/Users/tobias/Documents/BioSoundTutorial-master/vocSelTableSpectro.h5'\n",
    "pcInfo = '/Users/tobias/Documents/BioSoundTutorial-master/vocSpectroPC.pkl'\n",
    "\n",
    "# This is where you want to store eps of figures that will be generated.\n",
    "figdir = '/Users/tobias/Documents/BioSoundTutorial-master'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Looping through a set of bioSoundObjects to extract the spectrogram and storing them into a Pandas Data Frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1. Extract Spectrograms; normalize if desired; and compress by PCA\n",
    "\n",
    "Here we are doing the PC to store the data efficiently.  Unless you have a ton of data the classifier will only use a small number of these anyway.  The first PCA is to reduce from the ~25000 (for these data) space of spectrogram to a space of 50.  As you will see this is able to capture almost 90% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated space for all spectrograms\n",
      "(45, 200)\n"
     ]
    }
   ],
   "source": [
    "# Set true if you want to normalize all spectrograms.\n",
    "normFlg = True\n",
    "\n",
    "#nPCs is the number of PCs that will be used in the first dimensionality reduction\n",
    "nPCs = 50\n",
    "\n",
    "# Read first one to allocate space for np array\n",
    "count = 0\n",
    "shapeSpectro = []\n",
    "birdName = []\n",
    "callType = []\n",
    "for fname in os.listdir('.'):\n",
    "    if fname.endswith('.h5'):\n",
    "        myBioSound = BioSound()\n",
    "        myBioSound.readh5(fname)\n",
    "        \n",
    "        shapeSpectro.append(myBioSound.spectro.shape)\n",
    "        birdName.append(np.array2string(myBioSound.emitter)[2:-1])\n",
    "        callType.append(np.array2string(myBioSound.type)[2:-1])\n",
    "        \n",
    "        count += 1\n",
    "   \n",
    "shapeSpectro.sort()\n",
    "shapeDesired = (45, 200)\n",
    "\n",
    "X = np.zeros((count, shapeDesired[0]*shapeDesired[1]))\n",
    "print('Allocated space for all spectrograms')\n",
    "print(shapeDesired)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5031.446540880503"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myBioSound.fo[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "def pad_vector(vector, depth, constant_value=0):\n",
    "    vect_shape = vector.shape[:2]\n",
    "    pp = np.full(shape=(vect_shape[0], depth), fill_value=constant_value)\n",
    "    #pdb.set_trace()\n",
    "    vector = np.hstack(tup=(pp, vector))\n",
    "    #pdb.set_trace()\n",
    "    pv = np.hstack(tup=(vector, pp))\n",
    "    return pv\n",
    "\n",
    "def symmetric_padding(vector, shapedDesired):\n",
    "    # This function padds zeros to the left and right of the spectogram\n",
    "    difference = shapeDesired[1] - vector.shape[1]\n",
    "    number_of_zeros = 0\n",
    "    \n",
    "    if difference % 2 == 0: # If even, divide by 2\n",
    "        number_of_zeros = int(difference / 2)\n",
    "    else:\n",
    "        vector = vector[:,0:-1]\n",
    "        number_of_zeros = int( (difference+1) / 2 )\n",
    "    output_vector = pad_vector(vector, number_of_zeros,0)\n",
    "    return output_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\tobias\\appdata\\local\\temp\\ipykernel_14824\\3899343834.py\u001b[0m(37)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop again to extract spectrogram, store the in X and calculate PC \n",
    "\n",
    "# Looping through all the files\n",
    "count = 0\n",
    "list_of_spectros_lengths=[]\n",
    "do_symmetric_padding = True\n",
    "\n",
    "for fname in os.listdir('.'):\n",
    "    if fname.endswith('.h5'):\n",
    "        \n",
    "        # Allocate object and read data\n",
    "        myBioSound.readh5(fname)\n",
    "        \n",
    "        # Massage spectrogram as in matlab code (DFA_Calls_Julie)\n",
    "        if normFlg:  # Normalize by peak\n",
    "            myBioSound.spectro -= myBioSound.spectro.max()\n",
    "\n",
    "        # Set a 100 dB range threshold\n",
    "        maxAmp = myBioSound.spectro.max();\n",
    "        minAmp = maxAmp - 100;\n",
    "        myBioSound.spectro[myBioSound.spectro < minAmp] = minAmp;\n",
    "        shapeSpectro.append(myBioSound.spectro.shape)\n",
    "        list_of_spectros_lengths.append(myBioSound.spectro.shape[1])\n",
    "        if myBioSound.spectro.shape[1]<shapeDesired[1]:\n",
    "            if do_symmetric_padding == True:\n",
    "                #pdb.set_trace()\n",
    "                #print(fname)\n",
    "                try:\n",
    "                    X[count, :] = np.ravel(symmetric_padding(myBioSound.spectro, shapeDesired))\n",
    "                except:\n",
    "                    pdb.set_trace()\n",
    "            else: # Just padd at end\n",
    "                X[count, 0:myBioSound.spectro.size] = np.ravel(myBioSound.spectro[0:shapeDesired[0], :])\n",
    "        else:\n",
    "            X[count, :] = np.ravel(myBioSound.spectro[0:shapeDesired[0], 0:shapeDesired[1]])\n",
    "      \n",
    "        count +=1\n",
    "            \n",
    "print('Read %d files and spectrograms' % count)\n",
    "print('Performing PCA')\n",
    "\n",
    "pca = PCA(n_components=nPCs)\n",
    "Xr = pca.fit_transform(X)  \n",
    " \n",
    "# Write PCA information in pkl                         \n",
    "pcInfoFile = open(pcInfo, 'wb')\n",
    "\n",
    "pickle.dump(pca.components_, pcInfoFile)\n",
    "\n",
    "print('PCA Done: Wrote PC\\'s to pickle file %s' % pcInfoFile)\n",
    "print ('Variance explained is %.2f%%' % (sum(pca.explained_variance_ratio_)*100.0))\n",
    "\n",
    "# Add pd spectrograms to dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the PCs\n",
    "pca.fit(X)\n",
    "print(pca.components_.shape)\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"min spectrogram length: {min(list_of_spectros_lengths)}\")\n",
    "print(f\"max spectrogram length: {max(list_of_spectros_lengths)}\")\n",
    "avg_spectrogram_length = (np.mean(np.array(list_of_spectros_lengths)))\n",
    "print(f\"avg spectrogram length: {avg_spectrogram_length}\")\n",
    "from statistics import mode\n",
    "mode2 = mode(list_of_spectros_lengths)\n",
    "print(f\"mode of spectrogram length: {mode2}\")\n",
    "\n",
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=list_of_spectros_lengths, bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Call duration')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of call durations')\n",
    "plt.xlim(xmax=100)\n",
    "\n",
    "\n",
    "list_of_spectros_lengths.sort()\n",
    "ninety_fifth_point = list_of_spectros_lengths[int(len(list_of_spectros_lengths)*0.95)]\n",
    "print(f\"95th%-ile point: {ninety_fifth_point}\")\n",
    "\n",
    "median_point = list_of_spectros_lengths[int(len(list_of_spectros_lengths)*0.5)]\n",
    "print(f\"median point: {median_point}\")\n",
    "\n",
    "median_point = list_of_spectros_lengths[int(len(list_of_spectros_lengths)*0.000001)]\n",
    "print(f\".000001 point: {median_point}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the pandas data frame with all the spectrograms\n",
    "vocSelData = []\n",
    "for ic in range(count):         \n",
    "    vocSelData.append({\"Bird\": birdName[ic], \n",
    "                       \"Calltype\": callType[ic], \n",
    "                       \"Spectro\": X[ic]}) \n",
    "     \n",
    "\n",
    "# Make a panda data frame with all the data  \n",
    "print('Reprocessed %d files to make Panda Data Frame'%count)                    \n",
    "vocSelTable = pd.DataFrame(vocSelData)\n",
    "vocSelTable.to_hdf(tableStore, 'callTable', mode = 'w')\n",
    "print('Done: Wrote pandas data frame to h5 file %s' % tableStore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add deafness to the pandas table\n",
    "BatStatus_name = ['F11648', 'M14461', 'F14463', 'M14464', 'F65696', 'M71043', 'F71047', 'M71351', 'F71353', 'F71354'];\n",
    "BatStatus_sex = ['F', 'M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'F'];\n",
    "BatStatus_deaf = [0, 0, 1, 0, 0, 1, 1, 1, 0, 1];\n",
    "\n",
    "# Initialize name-deaf_status dict\n",
    "bat_name_to_deaf_dict = dict(zip(BatStatus_name,BatStatus_deaf))\n",
    "bat_name_to_sex_dict = dict(zip(BatStatus_name, BatStatus_sex))\n",
    "\n",
    "# Add deaf status to dictionary\n",
    "vocSelTable['isDeaf'] =  vocSelTable['Bird'].map(bat_name_to_deaf_dict) # Bird is actually Bat ID. \n",
    "isDeaf_array = np.array(vocSelTable['isDeaf'])\n",
    "print(isDeaf_array)\n",
    "\n",
    "\n",
    "vocSelTable['sex'] =  vocSelTable['Bird'].map(bat_name_to_sex_dict) # Bird is actually Bat ID. \n",
    "sex_array = np.array(vocSelTable['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocSelData = []\n",
    "for ic in range(count):         \n",
    "    vocSelData.append({ \"isDeaf\": isDeaf_array[ic],\n",
    "                       \"sex\": sex_array[ic],\n",
    "                       \"Bird\": birdName[ic], \n",
    "                       \"Calltype\": callType[ic], \n",
    "                       \"Spectro\": X[ic]}\n",
    "                       ) \n",
    "    \n",
    "# Make a panda data frame with all the data  \n",
    "print('Reprocessed %d files to make Panda Data Frame'%count)                    \n",
    "vocSelTable = pd.DataFrame(vocSelData)\n",
    "vocSelTable.to_hdf(tableStore, 'callTable', mode = 'w')\n",
    "print('Done: Wrote pandas data frame to h5 file %s' % tableStore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.  Run the Classifiers.  \n",
    "### You can also run only this code after reading vocSelTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can start here (after loading dependencies) or skip if you already have vocSelTable\n",
    "\n",
    "#Read the pandas table\n",
    "vocSelTable = pd.read_hdf(tableStore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is very similar to tutorial 4.\n",
    "\n",
    "#  Here we generate colors for each bird for plotting purposes:\n",
    "\n",
    "# Color code for bird ID\n",
    "birdColorStart = [(0/255.0, 230/255.0, 255/255.0),  \n",
    "             (255/255.0, 0/255.0, 0/255.0), \n",
    "             (255/255.0, 180/255.0, 255/255.0),\n",
    "             (140/255.0, 100/255.0, 185/255.0) ]\n",
    "\n",
    "\n",
    "\n",
    "birdNames = np.unique(vocSelTable['isDeaf'])\n",
    "\n",
    "# If you have a small number of birds you might want to choose specific colors\n",
    "birdColor = {}\n",
    "ib = 0\n",
    "for birdId in birdNames:\n",
    "    if ib < 4:\n",
    "       birdColor[birdId] = birdColorStart[ib] \n",
    "    else:\n",
    "       birdColor[birdId] = np.random.rand(3)\n",
    "    ib += 1\n",
    "    \n",
    "cValBirdAll = []\n",
    "for birdId in vocSelTable['isDeaf']:\n",
    "    cValBirdAll.append(birdColor[birdId])\n",
    "    \n",
    "cValBirdAll = np.asarray(cValBirdAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is very similar to tutorial 4.\n",
    "\n",
    "#  Now we perform the supervised cross-validated and regularized classification:\n",
    "\n",
    "# y is the grouping variable\n",
    "y = np.array(vocSelTable['isDeaf'])\n",
    "\n",
    "# X is the vector of features that will be used \n",
    "X = np.vstack(vocSelTable['Spectro'])\n",
    "\n",
    "# As always it is wise to exclude entries with missing data (should not happen here)\n",
    "nonanInd = (np.sum(np.isnan(X), axis = 1) == 0)\n",
    "\n",
    "groups = vocSelTable['Bird'][nonanInd]\n",
    "\n",
    "# The classifier. Comment in our out group_hold_out to do GroupStratifiedKFold\n",
    "ldaYes, qdaYes, rfYes, cvCount, ldaP, qdaP, rfP, nClasses, weights, weights_all = discriminatePlot(X[nonanInd], y[nonanInd], \n",
    "                                                                                      cValBirdAll[nonanInd], \n",
    "                                                                                      titleStr='Caller Spectro', \n",
    "                                                                                      figdir = figdir,\n",
    "                                                                                      plotFig = True,\n",
    "                                                                                     group_hold_out = groups)\n",
    "\n",
    "# Storing the results in a Pandas Data frame (usefull for compilation and further processing)\n",
    "d = {'Type': np.array(['CallerAdult']),\n",
    "     'Features': np.array(['Spectrogram']), \n",
    "     'LDA Correct' : np.array([ldaYes]), \n",
    "     'QDA Correct': np.array([qdaYes]),\n",
    "     'RF Correct': np.array([rfYes]),\n",
    "     'Tested' : np.array([cvCount]),\n",
    "     'nClasses' : np.array([nClasses]),\n",
    "     'LDA Pval' : np.array([ldaP]),\n",
    "     'QDA Pval': np.array([qdaP]),\n",
    "     'RF Pval': np.array([rfP])}\n",
    "     \n",
    "resultsDataFrame = pd.DataFrame(data = d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights_all.shape)\n",
    "weights_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaped = np.reshape(weights_all, shapeDesired)\n",
    "plt.imshow(shaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(myBioSound.fpsd,myBioSound.psd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myBioSound.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do in the future:\n",
    "1) Take the average of all deaf vs all control  myBioSound.psd's, and compare\n",
    "2) Look at correctly classified \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
